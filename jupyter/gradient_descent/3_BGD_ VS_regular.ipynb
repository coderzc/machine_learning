{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入真实数据进行训练并与正规方程解进行对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "X=boston.data\n",
    "y=boston.target\n",
    "\n",
    "X=X[y<50]\n",
    "y=y[y<50]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n正规方程解相关函数\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测函数\n",
    "def predict_normal(W,X_test):\n",
    "        X_b = np.hstack([np.ones((len(X_test),1)),X_test])\n",
    "        y_hat = X_b.dot(W)\n",
    "        return y_hat\n",
    "\n",
    "# 引入R^2进行评价\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算损失函数\n",
    "def J(W,X_b,y):\n",
    "    try:\n",
    "        return np.sum((y-X_b.dot(W))**2) / len(y)\n",
    "    except:\n",
    "        return float('inf')\n",
    "\n",
    "# 向量化计算梯度\n",
    "def dJ_vector(W,X_b,y):\n",
    "    return X_b.T.dot(X_b.dot(W) - y) * 2. / len(y)    \n",
    "    \n",
    "# 梯度下降法\n",
    "def gradient_descent_vector(init_w,X,y,eta=0.01,epsilon=1e-8,n_iters=1e4,init_b=0.):\n",
    "    \n",
    "    # 补1\n",
    "    X_b = np.hstack([np.ones((len(X),1)),X])\n",
    "    # 补b\n",
    "    W = np.hstack([init_b,init_w])\n",
    "    \n",
    "    i_iter=0\n",
    "    while i_iter<n_iters:\n",
    "        grad=dJ_vector(W,X_b,y)\n",
    "        last_W=W\n",
    "        W=W-eta*grad\n",
    "        if(abs(J(W,X_b,y)-J(last_W,X_b,y)) < epsilon):\n",
    "            break\n",
    "        i_iter += 1    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 正规方程解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.7 ms, sys: 9.32 ms, total: 30 ms\n",
      "Wall time: 46.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8129794056212809"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "系数: [-1.20354261e-01  3.64423279e-02 -3.61493155e-02  5.12978140e-02\n",
      " -1.15775825e+01  3.42740062e+00 -2.32311760e-02 -1.19487594e+00\n",
      "  2.60101728e-01 -1.40219119e-02 -8.35430488e-01  7.80472852e-03\n",
      " -3.80923751e-01]\n",
      "截距: 34.117399723229845\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "%time lin_reg.fit(X_train,y_train)\n",
    "lin_reg.score(X_test,y_test)\n",
    "\n",
    "print(\"系数:\",lin_reg.coef_)\n",
    "print(\"截距:\",lin_reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zc/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/Users/zc/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in square\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/zc/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1.42362e+01, 0.00000e+00, 1.81000e+01, 0.00000e+00, 6.93000e-01,\n",
       "        6.34300e+00, 1.00000e+02, 1.57410e+00, 2.40000e+01, 6.66000e+02,\n",
       "        2.02000e+01, 3.96900e+02, 2.03200e+01],\n",
       "       [3.67822e+00, 0.00000e+00, 1.81000e+01, 0.00000e+00, 7.70000e-01,\n",
       "        5.36200e+00, 9.62000e+01, 2.10360e+00, 2.40000e+01, 6.66000e+02,\n",
       "        2.02000e+01, 3.80790e+02, 1.01900e+01],\n",
       "       [1.04690e-01, 4.00000e+01, 6.41000e+00, 1.00000e+00, 4.47000e-01,\n",
       "        7.26700e+00, 4.90000e+01, 4.78720e+00, 4.00000e+00, 2.54000e+02,\n",
       "        1.76000e+01, 3.89250e+02, 6.05000e+00],\n",
       "       [1.15172e+00, 0.00000e+00, 8.14000e+00, 0.00000e+00, 5.38000e-01,\n",
       "        5.70100e+00, 9.50000e+01, 3.78720e+00, 4.00000e+00, 3.07000e+02,\n",
       "        2.10000e+01, 3.58770e+02, 1.83500e+01],\n",
       "       [6.58800e-02, 0.00000e+00, 2.46000e+00, 0.00000e+00, 4.88000e-01,\n",
       "        7.76500e+00, 8.33000e+01, 2.74100e+00, 3.00000e+00, 1.93000e+02,\n",
       "        1.78000e+01, 3.95560e+02, 7.56000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_w = np.zeros(X_train.shape[1])\n",
    "\n",
    "gradient_descent_vector(init_w,X_train,y_train)\n",
    "\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 真实数据之间的差距较大，相比较我们学习率太大，所以结果无法收敛，我们应该降低学习率**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27586818724477247"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "系数: [-0.10245704  0.11535876 -0.06248791  0.00207516  0.00447152  0.11954208\n",
      "  0.04684195  0.03460927 -0.00452122  0.00324507  0.1271939   0.04484862\n",
      " -0.22542441]\n",
      "截距: 0.011951606011577695\n"
     ]
    }
   ],
   "source": [
    "W_ = gradient_descent_vector(init_w,X_train,y_train,eta=1e-6)\n",
    "\n",
    "r2_score(y_test,predict_normal(W_,X_test))\n",
    "\n",
    "print(\"系数:\",W_[1:])\n",
    "print(\"截距:\",W_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 我们结果不是很好，有可能是学习率太小，使得我们在限定步数内梯度没有下降到最优点，我们尝试应该增大限定步数继续下降梯度**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 541 ms, total: 1min 14s\n",
      "Wall time: 41.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7542932581943915"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "系数: [-1.07889200e-01  5.91494760e-02 -5.72920411e-02  1.19334353e-01\n",
      "  2.07223623e-01  3.91254775e+00  1.50564949e-03 -5.36511902e-01\n",
      "  1.13424276e-01 -9.76209406e-03  5.35544815e-02  1.58440412e-02\n",
      " -3.78786162e-01]\n",
      "截距: 0.43522123962172593\n"
     ]
    }
   ],
   "source": [
    "%time W_ = gradient_descent_vector(init_w,X_train,y_train,eta=1e-6,n_iters=1e6)\n",
    "\n",
    "r2_score(y_test,predict_normal(W_,X_test))\n",
    "\n",
    "print(\"系数:\",W_[1:])\n",
    "print(\"截距:\",W_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 现在我们准确率有所提升，但还不是很理想，而且训练耗时较长\n",
    "这很有可能是因为数据各个特征量级相差较大，我们应该尝试对数据做归一化处理**\n",
    "\n",
    "<br/>\n",
    " <img src=\"../img/5.png\" width=\"500\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardScaler = StandardScaler()\n",
    "standardScaler.fit(X_train)\n",
    "\n",
    "X_train = standardScaler.transform(X_train)\n",
    "X_test = standardScaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 398 ms, sys: 6.09 ms, total: 404 ms\n",
      "Wall time: 230 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8129873310487505"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "系数: [-1.04042202  0.83093351 -0.24794356  0.01179456 -1.35034756  2.25074\n",
      " -0.66384353 -2.53568774  2.25572406 -2.34011572 -1.76565394  0.70923397\n",
      " -2.72677064]\n",
      "截距: 21.500765306122382\n"
     ]
    }
   ],
   "source": [
    "%time W_ = gradient_descent_vector(init_w,X_train,y_train)\n",
    "\n",
    "r2_score(y_test,predict_normal(W_,X_test))\n",
    "\n",
    "print(\"系数:\",W_[1:])\n",
    "print(\"截距:\",W_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降法的优势"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1000\n",
    "n = 50000\n",
    "\n",
    "big_X = np.random.normal(size=(m, n))\n",
    "\n",
    "true_W = np.random.uniform(0.0, 100.0, size=n+1)\n",
    "\n",
    "big_y = big_X.dot(true_W[1:]) + true_W[0] + np.random.normal(0., 10., size=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.2 s, sys: 649 ms, total: 6.85 s\n",
      "Wall time: 4.57 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "%time lin_reg.fit(big_X,big_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.43 s, sys: 278 ms, total: 2.71 s\n",
      "Wall time: 1.9 s\n"
     ]
    }
   ],
   "source": [
    "%time W_ = gradient_descent_vector(np.zeros(n),big_X,big_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 维数越大梯度下降法优势越明显，同时正规方程解的复杂度越大\n",
    "* 但样本数量很影响梯度下降法的性能，因为梯度计算的过程要每一个数据都要参与计算，所以我们将引入随机梯度下降法来优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
