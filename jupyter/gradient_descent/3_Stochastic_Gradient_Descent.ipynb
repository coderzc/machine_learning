{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机梯度下降法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/6.png\" width=\"500\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模拟退火思想：$\\eta =\\dfrac {t_{0}}{i_{iters}+t_{1}}$\n",
    "\n",
    "<img src=\"../img/7.png\" width=\"500\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现随机梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100000\n",
    "\n",
    "x = np.random.normal(size=m)\n",
    "X = x.reshape(-1,1)\n",
    "y = 4.*x + 3. + np.random.normal(0,3,size=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算梯度\n",
    "def dJ_vector(W,X_b_i,y_i):\n",
    "    return X_b_i.T.dot(X_b_i.dot(W) - y_i) * 2.\n",
    "\n",
    "# 梯度下降\n",
    "def sgd(init_w,X,y,t0=5,t1=50,n_iters=1e4,init_b=0.):\n",
    "    \n",
    "    # 退火算法计算学习率\n",
    "    def learning_rate(t):\n",
    "        return t0 / (t + t1)\n",
    "    \n",
    "    # 补1\n",
    "    X_b = np.hstack([np.ones((len(X),1)),X])\n",
    "    # 补b\n",
    "    W = np.hstack([init_b,init_w])\n",
    "    \n",
    "    for i_iter in range(n_iters):\n",
    "        rand_i=np.random.randint(len(X_b))\n",
    "        grad=dJ_vector(W,X_b[rand_i],y[rand_i])\n",
    "        W=W-learning_rate(i_iter)*grad\n",
    "        \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.051732346078063\n",
      "[4.00602278]\n",
      "CPU times: user 217 ms, sys: 3.89 ms, total: 221 ms\n",
      "Wall time: 224 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "init_w = np.zeros(X.shape[1])\n",
    "W_ = sgd(init_w,X,y,n_iters=len(X)//3)\n",
    "print(W_[0])\n",
    "print(W_[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为解决SGD随机性无法全面的使所有样本参与计算，改进一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算梯度\n",
    "def dJ_vector(W,X_b_i,y_i):\n",
    "    return X_b_i.T.dot(X_b_i.dot(W) - y_i) * 2.\n",
    "\n",
    "# 梯度下降\n",
    "def sgd2(init_w,X,y,t0=5,t1=50,n_iters=5,init_b=0.):\n",
    "    \n",
    "    # 退火算法计算学习率\n",
    "    def learning_rate(t):\n",
    "        return t0 / (t + t1)\n",
    "    \n",
    "    # 补1\n",
    "    X_b = np.hstack([np.ones((len(X),1)),X])\n",
    "    # 补b\n",
    "    W = np.hstack([init_b,init_w])\n",
    "    \n",
    "    # 此时n_iters 单纯代表循环次数，与m无关\n",
    "    for i_iter in range(n_iters):\n",
    "        m = len(X_b)\n",
    "        # 我们将矩阵乱序，然后每次使用一组计算梯度\n",
    "        indexs = np.random.permutation(m)\n",
    "        X_b_new = X_b[indexs]\n",
    "        y_new = y[indexs]\n",
    "        for i in range(m):\n",
    "            grad=dJ_vector(W,X_b_new[i],y_new[i])\n",
    "            W=W-learning_rate(i_iter*m+i)*grad\n",
    "            \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.011831485793552\n",
      "[4.004134]\n",
      "CPU times: user 851 ms, sys: 11.1 ms, total: 862 ms\n",
      "Wall time: 884 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "init_w = np.zeros(X.shape[1])\n",
    "W_ = sgd2(init_w,X,y,n_iters=2)\n",
    "print(W_[0])\n",
    "print(W_[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用真实的数据测试我们的SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入波士顿房产数据\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "X=boston.data\n",
    "y=boston.target\n",
    "\n",
    "X=X[y<50]\n",
    "y=y[y<50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.2 ,random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standardScaler = StandardScaler()\n",
    "standardScaler.fit(X_train)\n",
    "X_train_standard = standardScaler.transform(X_train)\n",
    "X_test_standard = standardScaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测函数\n",
    "def predict_normal(W,X_test):\n",
    "        X_b = np.hstack([np.ones((len(X_test),1)),X_test])\n",
    "        y_hat = X_b.dot(W)\n",
    "        return y_hat\n",
    "\n",
    "# 引入R^2进行评价\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.5 ms, sys: 2.52 ms, total: 16 ms\n",
      "Wall time: 12.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8129794056212809"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "系数: [-1.20354261e-01  3.64423279e-02 -3.61493155e-02  5.12978140e-02\n",
      " -1.15775825e+01  3.42740062e+00 -2.32311760e-02 -1.19487594e+00\n",
      "  2.60101728e-01 -1.40219119e-02 -8.35430488e-01  7.80472852e-03\n",
      " -3.80923751e-01]\n",
      "截距: 34.117399723229845\n"
     ]
    }
   ],
   "source": [
    "# 正规方程解\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "%time lin_reg.fit(X_train,y_train)\n",
    "r2_score(y_test,lin_reg.predict(X_test))\n",
    "\n",
    "print(\"系数:\",lin_reg.coef_)\n",
    "print(\"截距:\",lin_reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.6 ms, sys: 1.96 ms, total: 14.6 ms\n",
      "Wall time: 7.22 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8058104209961152"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "系数: [-0.74278529  0.4202707  -0.85441506  0.52013874 -1.55041305  2.35260848\n",
      " -0.53811922 -2.53880223  0.51701515 -0.40875924 -1.74174289  1.01033266\n",
      " -2.9560288 ]\n",
      "截距: 21.48293966262566\n"
     ]
    }
   ],
   "source": [
    "# SGD 随机梯度下降\n",
    "init_w = np.zeros(X_train_standard.shape[1])\n",
    "%time W_ = sgd2(init_w,X_train_standard,y_train,n_iters=2)\n",
    "r2_score(y_test,predict_normal(W_,X_test_standard))\n",
    "print(\"系数:\",W_[1:])\n",
    "print(\"截距:\",W_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 197 ms, sys: 3.59 ms, total: 200 ms\n",
      "Wall time: 104 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8127913496243248"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time W_ = sgd2(init_w,X_train_standard,y_train,n_iters=50)\n",
    "r2_score(y_test,predict_normal(W_,X_test_standard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn 中的SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.84 ms, sys: 2.02 ms, total: 7.87 ms\n",
      "Wall time: 3.62 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zc/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8030568596339946"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_reg = SGDRegressor()\n",
    "%time sgd_reg.fit(X_train_standard, y_train)\n",
    "sgd_reg.score(X_test_standard,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.2 ms, sys: 1.17 ms, total: 14.4 ms\n",
      "Wall time: 5.56 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zc/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
       "       n_iter=100, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8130791166551363"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 增大 n_iter \n",
    "sgd_reg = SGDRegressor(n_iter=100)\n",
    "%time sgd_reg.fit(X_train_standard, y_train)\n",
    "sgd_reg.score(X_test_standard,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
